\documentclass[
% twocolumn,
% hf,
]{ceurart}

\usepackage{woa-2022-psyke}

\sloppy

\begin{document}
\copyrightyear{2022}
\copyrightclause{Copyright for this paper by its authors.
	Use permitted under Creative Commons License Attribution 4.0
	International (CC BY 4.0).}

\conference{WOA 2022: Workshop ``From Objects to Agents'', September 1--3, 2022, Genoa, Italy}

%%
\title{Hypercube-based methods for symbolic knowledge extraction: towards a unified model}

%%
\author[1]{Federico Sabbatini}[%
orcid=0000-0002-0532-6777,
email=f.sabbatini1@studio.uniurb.it,
url=http://federicosabbatini.apice.unibo.it
]\cormark[1]
\address[1]{Dipartimento di Scienze Pure e Applicate (DiSPeA), Universit\`a di Urbino, Italy}

\author[2]{Giovanni Ciatto}[%
orcid=0000-0002-1841-8996,
email=giovanni.ciatto@unibo.it,
url=https://about.me/gciatto
]
\address[2]{Dipartimento di Informatica -- Scienza e Ingegneria (DISI), \textsc{Alma Mater Studiorum}---Universit\`a di Bologna, Italy}

\author[3]{Roberta Calegari}[%
orcid=0000-0003-3794-2942,
email=roberta.calegari@unibo.it,
url=http://robertacalegari.apice.unibo.it
]
\address[3]{Alma Mater Research Institute for Human-Centered Artificial Intelligence, \textsc{Alma Mater Studiorum}---Universit\`a di Bologna, Italy}

\author[2]{Andrea Omicini}[%
orcid=0000-0002-6655-3869,
email=andrea.omicini@unibo.it,
url=http://andreaomicini.apice.unibo.it
]

\cortext[1]{Corresponding author.}

\begin{abstract}
Symbolic knowledge-extraction (SKE) algorithms proposed by the explainable artificial intelligence community to obtain human-intelligible explanations for opaque machine learning predictors are currently being studied and developed with growing interest.
%
However, choosing the most adequate extraction procedure amongst the many existing into the literature is becoming more and more challenging, as the amount of available method increases.
%
In fact, most of the proposed algorithms come with \emph{constraints} concerning the situations they can be applied into.

In this paper we focus upon a quite general class of SKE techniques, namely \emph{hypercube-based} methods.
%
Despite being commonly considered regression-specific, in this paper we discuss why hypercube-based SKE methods are flexible enough to deal with classification problems as well.
%
More generally, we propose a common metamodel for hypercube-based methods, and we show how they can be exploited to perform SKE on datasets, predictors, or learning tasks of any sort.
%
% We show that further manipulations may be horizontally enabled for a large class of knowledge extractors without the need to revise their algorithms, but only adding our proposed generalisation.
%
We also report as a concrete example the implementation of the proposed generalisation in the \psyke{} framework.
\end{abstract}

%%
%% Keywords.
\begin{keywords}
	explainable AI 
	\sep
  	knowledge extraction 
	\sep
	interpretable prediction 
	\sep
  	PSyKE
\end{keywords}

\maketitle

\section{Introduction}

% \gcnote{Leggete la nuova intro \& abstract. Se vi piace ristrutturiamo il paper, se no rollbackiamo e teniamo la versione di fede.}

% Many everyday tasks are currently carried out mainly via machine learning (ML) models~\cite{rocha2012far}.
% %
% Their increasing ubiquity descends from the impressive predictive performance they exhibit when used to support decision making in a wide variety of application fields, for instance customer profiling, financial forecasting, speech and image recognition, etc.
% %
% These data-driven predictors are trained upon a given amount of input instances, used to tune their internal parameters with the objective of minimising a predefined loss function w.r.t.\ training data.
% %
% Since the acquired knowledge is sub-symbolically stored in the form of parameter values, they are not directly interpretable from the human perspective, so the term \emph{black box} (BB) is used to refer these \emph{opaque} ML predictors.
% %
% Despite the lacking of human interpretability, BB models are anyway adopted thanks to their performance.

% There exist, however, critical applications areas -- highly impacting, for instance, in finance, law, healthcare or other domains involving human health and wealth -- where humans beings must be capable of understanding and explaining the obtained predictions, or else discard them as unacceptable.
% %
% Several methodologies have been proposed by the explainable artificial intelligence community to overcome the issues deriving from the lack of explainability~\cite{guidotti2018survey}.
% %
% The first consists of uniquely relying on \emph{interpretable} predictors~\cite{Rudin2019}, as, for instance, generalised linear models and decision trees, in order to obtain trained models explainable by construction.
% %
% This solution may bring negative repercussions on the overall predictive performance of the model, since it excludes some of the most promising ML algorithms, as artificial neural networks.
% %
% Another strategy is the reverse-engineering of the BB inner operation to derive \emph{post-hoc} explanations~\cite{KENNY2021103459}, for example via symbolic knowledge extraction (SKE).
% %
% This second solution allow data scientists to associate human-comprehensible knowledge to outputs given by prediction-effective, but opaque, algorithms.
% %
% The focus of this paper is on the latter strategy.

Symbolic knowledge extraction (SKE) is a powerful tool within the scope of explainable artificial intelligence (XAI).
%
It enables reverse-engineering of the black-box machine learning algorithms---which are nowadays exploited in many AI tasks~\cite{rocha2012far}.
%
Thanks to SKE, data scientists can associate human-comprehensible, \emph{post-hoc} explanations~\cite{KENNY2021103459} to the recommendations or decisions computed by most common prediction-effective -- yet, poorly interpretable -- algorithms.
%
To cite some examples, SKE is widely adopted to credit-risk evaluation \cite{baesens2003using,baesens2001building,steiner2006using}, medical diagnosis -- i.e., to make early breast cancer prognosis predictions \cite{franco2007early} and for recognising hepatobiliary disorders \cite{hayashi2000comparison} or other diseases and dysfunctions \cite{bologna1997three} --, credit card screening \cite{setiono2011rule}, intrusion detection systems \cite{hofmann2003rule}, and keyword extraction \cite{azcarraga2012keyword}.

The basic idea behind SKE is to construct \emph{symbolic} (hence, interpretable) models mimicking the behaviour of the pre-existing black-box predictors to be explained.
%
Such symbolic models should describe the corresponding black boxes in terms of the outputs they provide as responses to (classes of) inputs values.
%
Symbols, in particular, may consist of intelligible knowledge, e.g., lists or trees of \emph{logic rules} that can be exploited to obtain predictions as well as to better understand the underlying predictor.
%
In other words, symbols are both human- and machine-interpretable.

Because of the many SKE techniques available in the literature, selecting the most appropriate SKE algorithm for any given learning task may easily become cumbersome.
%
Difficulties may arise because of the intrinsic design choices behind each extraction algorithm.
%
In fact, SKE algorithms may commonly target specific learning tasks (classification or regression), specific sorts of ML predictors (e.g. neural networks, SVM, linear models, etc.), or specific sorts of training data (e.g. continuous, categorical, or binary).
%
% The latter can be bypassed by adopting \emph{pedagogical} extractors, working upon any kind of BB without taking into consideration its kind (e.g., if it is a neural network, a support-vector machine or a random forest predictor), nor its internal architecture (e.g., number of layers and neurons in neural networks).
% %
% As for the input features, they can be mapped from one category to another by performing some manipulations.
% %
% Algorithms accepting numerical continuous features also work with numerical discrete and binary inputs.
% %
% Categorical features may be easily converted into numerical by an enumeration.
% %
% On the other hand, algorithms designed to accept discrete features obviously accept binary features too, and they may work on continuous data if they are previously transformed, e.g., via discretisation.
% %
% Finally, any kind of feature can be traced back to binary values by applying one-hot encoding to discrete (or discretised) features.
% %
% By taking in considerations all these observations, it is possible to consider as overcame issues related to the nature of input features.
% %
% A different situation describe the kind of the task at hand.
%
% The majority of existing SKE techniques are exclusively designed for supervised classification (e.g.,~\cite{craven1994using,craven1996extracting}) or regression (e.g.,~\cite{huysmans2006iter,gridex-extraamas2021}).
% %
% Only few exceptions may be applied to both of them, as \cart{}~\cite{breiman1984classification}.
% %
% The inability to switch from a task to another comes with two major disadvantages for users:
% %
% \begin{inlinelist}
% 	\item the need to implement/learn how to tune a larger number of algorithms, since they are not general-purpose, and
% 	\item the impossibility to assess the performance of a (new) procedure over a wide range of test applications.
% \end{inlinelist}

In this paper, we focus upon a quite general class of SKE techniques, namely \emph{hypercube-based} methods.
%
Methods of such sort extract symbolic knowledge by querying black-box predictors as oracles, and by recursively partitioning the input spaces of these black boxes into several hyper-cubes---hence following a divide-et-impera approach.
%
Despite being commonly considered regression-specific, we show that hypercube-based SKE methods are flexible enough to deal with classification problems as well.
%
More generally, we propose a common metamodel for hypercube-based methods, and we show how they can be exploited to perform SKE on datasets, predictors, or learning tasks of any sort.

Accordingly, the contribution of this paper is manifold.
%
First, we provide a general and abstract description of any hypercube-based SKE workflow.
%
Second, we compare existing hypercube-based methods (e.g. \iter{}~\cite{huysmans2006iter} and \gridex{}~\cite{gridex-extraamas2021}) w.r.t. to the way they partition the input space, approximate black-box decisions, and construct the extracted symbolic knowledge.
%
Third, we discuss how hypercube-based methods can be engineered to provide full support to supervised learning tasks---there including regression and classification ones.
%
Finally, to 
%
% In this paper we propose a generalisation of SKE techniques designed for regression tasks, aimed at extending the application of algorithms
% %
% \begin{inlinelist}
% 	\item based on aggregate computations (e.g., averaging output values), and
% 	\item adopting similarity-based criteria between input training data or output predictions (usually w.r.t.\ a user-defined threshold).
% \end{inlinelist}
% %
% Under this perspective, \iter{}~\cite{huysmans2006iter} and \gridex{}~\cite{gridex-extraamas2021} are perfect examples.
% %
% Thus, we 
demonstrate the versatility of hypercube-based methods, we analyse disparate SKE scenarios via the \psyke{} framework~\cite{psyke-woa2021,psyke-ia2022,psyke-extraamas2022}---that is, a platform combining SKE and Semantic Web to provide human-interpretability and intelligent agent-interoperability for BB-based machine learning tasks.
%
% Finally, we push forward our considerations to overcome another limitation of SKE techniques for regression, that is the constant output value provided by many of them, introducing an undesired discretisation of the predictions and thus a possible worsening of the predictive performance.
%
% We show that it is possible to obtain better results by generalising these algorithms according to our method in order to obtain outputs in the form of linear combination of the input variables.

Accordingly, the remainder of this paper is organised as follows.
%
\Cref{sec:state} describes the state of the art for SKE as well as some background notion to fully understand the work.
%
\Cref{sec:contribution} presents our meta-model for hypercube-based methods and compares most relevant methods from the literature, which are then exemplified in \Cref{sec:experiments}.
%
Finally, conclusions are drawn in \Cref{sec:conclusions}.

\section{State of the Art}\label{sec:state}

In the following we provide details about the state of the art for symbolic knowledge extraction and the \psyke{} platform.
%
We focus in particular on the extraction algorithms cited in \Cref{sec:experiments} to give a practical demonstration of out methodology.
%
Is should be noticed that we restricted our experiments to pedagogical regression extractors inducing hypercubic partitionings of the input feature space.

\subsection{Knowledge Extraction}\label{ssec:extraction}

Computational systems are considered \emph{interpretable} when humans are able to easily understand its operation and outcomes~\cite{agentbasedxai-aamas2020}.
%
However, nowadays decision support systems often rely on ML models having excellent predictive capabilities at the expense of interpretability.
%
These \emph{sub-symbolic} predictors of increasing complexity, that learn input-output relations from data and store them as internal parameters, do not provide any kind of \emph{symbolic} representation of the acquired knowledge, thus lacking of an interpretable representation to the benefit of human users.
%
ML algorithms are defined as \emph{black boxes} for this reason~\cite{Lipton2018}.

It is possible to preserve the impressive BB predictive performance and, at the same time, obtain human-intelligible clues or explanations regarding the BB behaviour by substituting the opaque model with a mimicking interpretable surrogate.
%
The \xai{} community, indeed, have proposed a number of means to produce \emph{ex-post} explanations for sub-symbolic predictors in the form of surrogate models based on sets of rules extracted from the underlying opaque model.
%
Amongst the proposals there are methods to extract lists~\cite{craven1994using,huysmans2006iter,gridex-extraamas2021} or trees~\cite{craven1996extracting,breiman1984classification} of logic rules, usually if-then-else, \mofn{} or fuzzy.
%
SKE is of particular importance also for another reason.
%
Indeed, it may enable further manipulations, for instance to merge the \emph{know-how} of different BB models \cite{xmas-aiiot2019}.

Knowledge extraction algorithms can be categorised along three orthogonal dimensions~\cite{xaisurvey-ia14}:
%
\begin{inlinelist}
    \item\label{item:category:learning-task} supported learning tasks,
    \item\label{item:category:knowledge-form} shape of the symbolic knowledge provided in output,
    \item\label{item:category:translucency} the supported underlying ML models, usually known as \emph{translucency}.
\end{inlinelist}

Supporting tasks (\cref{item:category:learning-task}) are usually supervised classification or regression.
%
To the best of out knowledge, so far only supervised machine learning tasks have been considered by SKE, thus neglecting unsupervised or reinforcement learning tasks.
%
A cluster of SKE algorithms can only explain BB classifiers -- e.g.\ Rule-extraction-as-learning~\cite{craven1994using}, \trepan~\cite{craven1996extracting} and others \cite{barakat2005eclectic,martens2007comprehensible} --, while a different cluster is designed to support BB regressors---e.g., \iter~\cite{huysmans2006iter}, \gridex~\cite{gridex-extraamas2021}, \gridrex{}~\cite{gridrex-kr2022} and others~\cite{setiono2002extraction,schmitz1999ann,saito2002extracting}.
%
Finally, a little subset of SKE techniques are able to handle both tasks, as for the case of \textsc{G-Rex}~\cite{grex-icdm2008} and \cart~\cite{breiman1984classification}.

As for the shape of the output knowledge (\cref{item:category:knowledge-form}), decision rules \cite{freitas2014comprehensible,huysmans2011empirical,murphy1991id2} and trees \cite{quinlan1993c4,simplifyingdt-ijmms27} are usually considered the most human-understandable way to represent knowledge.
%
For this reason the majority of SKE methods produce one of these two structures as output.
%
Regardless of the shape, conditions describing decision rules and nodes are expressed by using the same input/output data types adopted to train the underlying BB.
%
For instance, SKE procedures applied to classifiers accepting $N$-dimensional numerical data and providing $K$ distinct output classes will produce rule lists or trees involving a certain number of \emph{predicates} over $N$ input variables $x_1, \ldots, x_n$ and having $K$ possible outcomes.
%
A further categorisation may be performed w.r.t.\ the kind of predicates contained in the output knowledge.
%
In particular, it is possible to observe conjunctions or disjunctions of inequalities (e.g.\ $x_i \gtrless c$) as well as inclusions in or exclusions from intervals (e.g.\ $x_i \in [l, u]$) for numerical data.
%
Categorical data are usually associated to equalities (e.g.\ $x_i = c$) and set-inclusions (e.g., $x_i \in \{c_1, c_2, \ldots \}$).
%
\mofn{} or fuzzy rules are other available alternatives for boolean/discrete or continuous data, respectively.

Finally, The translucency dimension \cite{andrews1995survey} (\cref{item:category:translucency}) represents the strategy adopted by the SKE algorithm to obtain interpretable knowledge from a BB.
%
In particular, extractors may be \emph{decompositional}, \emph{pedagogical} or \emph{eclectic}.
%
Decompositional techniques consider the internal structure of the underlying black box, together with inputs and provided outputs.
%
This implies that each algorithm is bounded to a specific ML predictor, possibly having constraints on the internal structures.
%
For instance, techniques analysing neural network connections are not applicable to support-vector machines and procedures explicitly designed for 3-layered networks are not suitable for deep ones.
%
On the other hand, pedagogical methods only observe the BB response to particular inputs.
%
For this reason pedagogical extractors do not present any limitation on the underlying predictor and thus they may be applied regardless of the BB nature.
%
Summing up, they are usually more general and potentially less precise, but considerations about the output performance strictly depend on the task at hand.
%
Finally, eclectic procedures mix elements of the two aforementioned categories.
%
Since some kind of internal structure inspection is performed, it is possible to encompass them in the wider decompositional category.

To evaluate the quality of SKE techniques different indicators are exploited, depending on the task to solve.
%
Common choices are readability, fidelity and predictive performance measurements \cite{towell1993extracting}.
%
The former expresses how interpretable is the output knowledge from the human perspective.
%
It is generally evaluated through the number of extracted rules and the number of constraints per rule.
%
Fidelity is related to the capability of the extracted knowledge to mimic the underlying BB predictions, whereas predictive performance measurements are assessed by comparing the predictions drawn from the extracted knowledge with the expected data.
%
Measurements involving predictions should be assessed via the same scoring function used for the underlying BB---which in turn strictly depends on the performed task.
%
Classifiers are usually evaluated via accuracy, precision, recall, and F1-score.
%
Conversely, common metrics for regressors are the mean absolute/squared error (MAE/MSE) and the R${^2}$ score.

\subsection{Extraction algorithms}\label{ssec:algorithms}

\paragraph{\iter}\label{par:iter}

\iter{}~\cite{huysmans2006iter} is a pedagogical technique producing \emph{if-then} logic rules from a BB predictor and a training set.
%
It assumes that all the input features are continuous, as the outputs.
%
The training set is usually the same adopted to train the black box.
%
The underlying predictor may belong to any category, since the procedure only considers its inputs and corresponding outputs.

The algorithm is based on the iterative creation and expansion of hypercubes inside the input feature space, until a maximum number of iterations is reached or, otherwise, the whole input space is covered.
%
The expansion may terminate also if it is not possible to further expand the hypercubes.
%
In those cases additional cubes may be created to cover the remaining space.

The extraction of knowledge is performed by associating a human-readable logic rule to each hypercube.
%
Output rules have the following format:
%
\begin{equation*}
	\text{Output is ~} C \text{~ if ~} X_1 \in [l_1, u_1], X_2 \in [l_2, u_2], ..., X_n \in [l_n, u_n],
\end{equation*}
%
where $C$ is a constant (real-valued) output and $X_1, X_2, ..., X_n$ are input variables assuming values included in the intervals described by corresponding lower-bounds $l_i$ and upper-bounds $u_i$.
%
Thus, the rule preconditions describe an $n$-dimensional hypercube.

\iter{} performs averaging operations to associate output values to hypercubes.
%
Indeed, for each cube, \iter{} selects all the training samples inside it and calculates the mean prediction by using the underlying BB as an oracle.
%
If the training samples are not enough to satisfy the minimum amount specified by the user, extra random samples are generated and predicted together with the others.

\iter{} also takes advantage of a similarity criterion to expand the hypercubes.
%
Indeed, at every iteration all the possible expansions around each cube are considered, but only one is performed, i.e., the one capable of expanding a cube towards the most similar input space region.
%
Similarity is calculated via mean absolute difference between the output values of the cubes to be expanded and the eligible cubes around them.

\paragraph{\gridex{} and \gridrex{}}\label{par:gridex}

\gridex~\cite{gridex-extraamas2021} is another pedagogical extraction algorithm for regressors, to be considered as an extension of \iter{} aimed at overcoming its major drawback, i.e., the non-exhaustivity of its output rules.
%
\gridex{} achieves this goal because it is exhaustive by design.
%
Both algorithms are applicable under the same circumstances regarding input features and produce lists of logic rules describing hypercubes associated to constant output values, that represent the interpretable predictions.
%
Differently from \iter{}, \gridex{} adopts a top-down approach to split the input feature space into hypercubes.
%
It iteratively partitions the \emph{whole} space according to some defined strategy, marking at each iteration if the created partitions are \emph{negligible} (i.e., they contain no training samples, so they are discarded since it is not relevant to have rules associated to them), \emph{eligible} for further partitioning (if they contain samples that are not enough \emph{similar}), or \emph{permanent} (otherwise, if they contain similar training instances and, thus, these cubes should have a good predictive performance).
%
Strategies to split the input space are \emph{fixed}, if the user specifies for each iterations how many partitions have to be performed along all the input dimensions, or \emph{adaptive}, if the number of splits is determined through the relevance of each input feature w.r.t.\ the output variable.
%
The output value of each cube is calculated as for \iter{}, so \gridex{} too is not able to produce actual regression rules.
%
Similarity between samples is assessed through the output value standard deviation of all the instances included inside a hypercube.
%
If the standard deviation is below a user-defined threshold, then the cube only contains similar samples and it is no further partitioned.
%
Otherwise, \gridex{} attempts to split the cube in smaller regions, possibly enclosing more similar samples.
%
Since the readability of the output model depends on the number of extracted rules, it is of paramount importance to keep it as low as possible.
%
For this reason a merging phase is performed after every splitting iteration as an optimisation to reduce the number of rules.
%
Indeed, adjacent cubes are pairwise merged according to a similarity criterion on the contained samples.
%
The merging phase is iterative: at each step are merged only the two adjacent cubes resulting in the merged hypercube having the lowest standard deviation, and it terminates when it is not possible to further merge cubes without exceeding the standard deviation user-defined threshold.

On the other hand, \gridrex{}~\cite{gridrex-kr2022} is a first attempt to apply the generalisation proposed in this work to \gridex{}.
%
Indeed, it is able to extract fully regressive rules, having as postconditions a linear combination of the input variables.
%
All the other details are identical to those described for \gridex{}, but it is able to achieve better predictive performance, fidelity and readability than \gridex{}

\paragraph{\cart}\label{par:cart}

\cart{}~\cite{breiman1984classification} is an algorithm building decision trees for classification or regression tasks.
%
\cart{} is not properly a SKE procedure, but it is possible to apply it to BB predictions instead of actual data, in order to obtain an interpretable ML predictor mimicking the underling BB.
%
Since \cart{} produces a tree, it is straightforward to convert it into a rule tree, since each tree node corresponds to a constraint on an input variable and, consequently, each path from the root to leaves constitutes a single human-interpretable rule to perform classification or regression.
%
The \cart{} algorithm can be summarised as follows:
%
\begin{inlinelist}
	\item initialise the root node of the tree;
	\item find optimal splits to add nodes (internal and leaves) accordingly;
	\item terminate the algorithm on the basis of one or more criteria---e.g., amount of rules or tree depth.
\end{inlinelist}
%
Pruning techniques may be exploited after the extraction to reduce the number of leaves and, thus, of output rules.

\subsection{\psyke}\label{ssec:psyke}

\begin{figure}
\centering
	\includegraphics[width=\linewidth]{figures/Psyke.pdf}
	\caption{\psyke{} design.}
	\label{fig:psyke-design}
\end{figure}

\input{tables/tab-algos.tex}

The \psyke{}~\cite{psyke-woa2021,psyke-ia2022} software library is a Python framework providing general-purpose support to SKE.
%
It can be exploited to obtain logic rules from BB classifiers and regressors via several pedagogical extraction methods.
%
Its unified API allow users to select the most adequate procedure with few lines of code, also allowing fast comparison between different alternatives.
%
At the time of writing, \psyke{} supports 6 state-of-the-art SKE algorithms, reported on the top of \Cref{fig:psyke-design} (see \Cref{tab:psyke} for further details), allowing researchers and data scientists to exploit them without the need to implement and test them.

As shown in \Cref{fig:psyke-design}, the \psyke{} design is developed around the notion of \emph{extractor}, intended as any algorithm accepting as input a ML predictor (classifier or regressor) together with the data set used to train it, and providing as output a \emph{theory} of \emph{logic} rules extracted from the predictor.
%
\psyke{} extractors need additional information about the data set to give more human-interpretability to the extracted knowledge.
In particular, a schema of the data set can be given as input to formally describe input and output feature names and types.

\psyke{} also exhibits utilities to manipulate the data set and perform feature engineering, for instance procedures to discretise or scale continuous features and to one-hot encode discrete/discretised features.
%
In addition, there are automatic procedures to select the optimal parameters of the extractors, which manual tuning may be challenging for human users.

As for the knowledge provided in output by extractors, it is possible to choose between two options:
\begin{inlinelist}
	\item a Prolog theory composed of human-intelligible clauses, possibly simplified to ease readability;
	\item an OWL ontology having agent-interpretable SWRL rules, to pursue interoperability between intelligent agents~\cite{psyke-extraamas2022}.
\end{inlinelist}
%
Input data as well may follow Semantic Web encoding, so \psyke{} extractors accept tabular data or knowledge graphs stored in OWL ontologies.

\section{Hypercube-based methods}\label{sec:contribution}

In this section, we provide a general model of hypercube-based knowledge extractors.
%
We then delve into the details of different algorithms from the literature, and we discuss how they match the model.

\subsection{Unified Model}

Hypercube-base extraction methods are \emph{pedagogical} extraction procedures which can operate on trained ML predictors of any sort.
%
They consider the predictor $P$ undergoing extraction as an oracle to be queried multiple times, in order to find a partitioning $H_1 \cup \ldots \cup H_n$ of its input space $\mathcal{X}$ such that the output space $\mathcal{Y}$ can be concisely and correctly expressed for each partition.
%
Hence, they extract knowledge in the form of rule lists or trees, where each rule carries attempts to describe the outcome of $P$ in a particular hypercube $H_i \subseteq \mathcal{X}$. 
%
More formally: 
%
\[ \mathbf{x} \in H_i \rightarrow (~\mathbf{y} = f_i(\mathbf{x})~) \]  
%
to be read as ``if the input vector $\mathbf{x} \in \mathcal{X}$ is in some hypercube $H_i$, then the prediction $\mathbf{y} \in \mathcal{Y}$ is $f_i(\mathbf{x})$''.
%
Notice that each hypercube $H_i$ is a partition of the input space $\mathcal{X}$, and it comes with a function $f_i$ approximating $P$ within that hypercube.
%
More formally: $f_i(\mathbf{x}) \approx P(\mathbf{x}),~\forall \mathbf{x} \in H_i$.

Regardless of its technical details, hypercube-based extraction procedures should then attempt to select hypercubes and local approximation functions in such a way to maximise the fidelity of the overall rule set/list w.r.t. $P$.
%
To do so, they follow a quite liner workflow, may be roughly summarised in 3 steps, namely:
%
\begin{enumerate}
	\item partition the input space into disjoint hypercubes $H_1 \cup \ldots \cup H_n$, following some strategy and according to defined constraints;
	% %
	% \begin{itemize}
	% 	\item e.g. one may be willing to minimise $n$ while maximising the size of each $H_i$
	% \end{itemize}
	\item approximate the prediction of $P$ for each hypercube $H_i$, via some function $f_i$; and
	% %
	% \begin{itemize}
	% 	\item e.g. one may be willing to maximise the similarity among $P$ and $f_i$ in $H_i$
	% \end{itemize}
	\item create a rule set where each rule \emph{concisely} represents $H_i$ and $f_i$ to describe the behaviour of $P$ in $H_i$.
\end{enumerate}
%
% It is important to notice that hypercube-based extractors produce as output a predictive rule per found partition.

In the following, we delve into the details of all such phases, individually.

\subsubsection{Input space partitioning}

The input space partitioning is s recursive computation aimed at finding the optimal amount, shape and size of hypercubes w.r.t.\ some \emph{desiderata}, such as:
%
\begin{inlinelist}
	\item covering the whole input space;
	\item obtaining disjoint regions;
	\item minimising the regions' amount;
	\item maximising the similarity amongst the samples inside single regions;
	\item minimising the predictive error correlated to each partition.
\end{inlinelist}

It is not possible to satisfy all these conditions at once, especially when dealing with high-dimensional data sets.
%
For this reason, some requirements may be relaxed.
%
For instance, the input space coverage may be limited only to the interesting input regions, neglecting the others.
%
A region may be defined as interesting if it contains training samples, and thus it is probable to have instances belonging to it to be predicted in the future.
%
Alternatively, the partitioning process may terminate after a predefined number of iterations, as some existing algorithms actually do.
%
However, this may lead to the indiscriminate exclusion of input regions that, conversely, are not negligible, resulting in the impossibility for the explainable model to provide predictions for a subset of input instances.

Disjoint regions may be relaxed into hierarchical or fuzzy regions, possibly mapped into non-overlapping rules, in order to have unambiguous output predictions.

The amount of found regions, strictly tied with the interpretable model readability (since this property decreases by increasing the number of regions), is usually controlled by the remaining conditions regarding similarity and predictive error, that in turn are usually inversely proportional between each other.
%
The capability of grouping together similar samples enable the creation of aggregate rules that capture well the average behaviour of instances belonging to the same region.
%
This corresponds to local rules having low predictive errors.
%
The following paragraphs explain in more details how to assess instance similarity and subregion predictive error for different possible scenarios.

\paragraph{Similarity amongst instances}

Subregions of the input feature space may be considered similar according to the following definitions:
%
\begin{description}
	\item[input closeness] if the input variables of both subregions have values ranging in similar domains, as for the case of adjacent disjoint or overlapping regions;
	\item [output closeness] if the output associated to the instances in the 2 subregions may be defined similar.
\end{description}
%
While it is straightforward to check input closeness (e.g., through Euclidean distance), the same cannot be stated for the output closeness, which depends on the task at hand.
%
The simplest case is for classification, since two subregions $d_1$ and $d_2$ satisfy output closeness if a predictor $P$ provides as most frequent output the same label for both subregions:
%
\begin{equation}
	sim(P, d_1, d_2) = 
	\begin{cases}
		True \text{~~~~~~if~} mode(P(d_1)) = mode(P(d_2))\\
		False \text{~~~~~otherwise}.\\
	\end{cases}\,\label{eq:simClass}
\end{equation}

In the case of regression with constant outputs, similarity may be expressed as a function of the absolute difference between the mean output predictions performed by the predictor $P$ on the two subregions $d_1$ and $d_2$:
%
\begin{equation}
	sim(P, d_1, d_2) = 
	\begin{cases}
		True \text{~~~~~~if~} |\overline{P(d_1)} - \overline{P(d_2)}| < \theta\\
		False \text{~~~~~otherwise},\\
	\end{cases}\,\label{eq:simRegK}
\end{equation}
%
where $\theta$ is a parameter defining the strictness of the similarity criterion.

Of course, this metrics is not suitable to recognise regions dominated by regression laws, since they may assume very different output values simply by changing (some of) the inputs.
%
In this case a more complex solution is required.
%
We propose the following metrics:
\begin{equation}
	sim(P, d_1, d_2) = 
	\begin{cases}
		True \text{~~~~~~if~} e(f, d_1 \cup d_2) <= 0.5 (e(f_1, d_1) + e(f_2, d_2))\\
		False \text{~~~~~otherwise,}\\
	\end{cases}\,\label{eq:simRegLin}
\end{equation}
where $e(f, d)$ is the mean absolute error of the linear function $f$ in approximating the input/output relationship for data instances in $d$.
%
The semantics of \Cref{eq:simRegLin} is the following: $d_1$ and $d_2$ are similar if
\begin{inlinelist}
	\item it is possible to merge the two regions,
	\item to find a linear combination of the input variables representing the input/output relationship of the merged region, and
	\item to have a performance for the found linear combination that is not worse than the average performance of the linear functions $f_1, f_2$ associated to the corresponding separated subregions.
\end{inlinelist}

\input{figures/fig-gen-sim.tex}

In \Cref{fig:general-sim} are reported examples of similarity assessments calculated for a generalised extractor applied to a classification task (\Cref{fig:gs1}) and to a regression task (\Cref{fig:gs2,fig:gs3}).
%
Figures concerning the regression task represent constant and non-constant outputs, respectively.
%
The example assumes a 2-dimensional data set with continuous input features both ranging in the interval [0, 5].
%
In the Figures cubes to be expanded/merged are those having coloured background.
%
Possible adjacent cubes to be joined to them are represented as cubes having no background.
%
Adjacent cubes that are similar to the cube to be expanded are represented with hatched background.
%
It worths noting that for the example depicted in \Cref{fig:gs2} a similarity threshold $\theta$ equal to 5.0 has been chosen.
%
In \Cref{fig:gs3} the predictive errors corresponding to the adjacent hypercubes as well as the calculated errors of the possible merged regions are omitted to keep the image clearer.

\paragraph{Predictive error assessment}

A generalised metrics is necessary to assess the predictive performance of a rule or set of rules for both classifications and regressions.
%
We propose as error function for an extractor $E$ applied to a data set $D$ the following:
%
\begin{equation}
	err(E, D) = 
	\begin{cases}
		mae(E, D) \text{~~~~~~~~~~~(regression)}\\
		1 - acc(E, D) \text{~~~~~~(classification),}\\
	\end{cases}\,\label{eq:error}
\end{equation}
%
where $mae(E, D)$ and $acc(E, D)$ are the mean absolute error and the classification accuracy score, respectively, calculated on the output predictions obtained via the rules extracted by $E$ for the data set $D$ w.r.t.\ the expected outputs for $D$.

\input{figures/fig-gen-err.tex}

In \Cref{fig:general-error} are reported examples of predictive errors measured for a generalised extractor.
%
The three plots follow the same logic as \Cref{fig:general-sim}.

\subsubsection{Approximating decisions}

As for the approximation of output decisions associated to input regions, they are usually computed on the basis of the predictions provided by the underlying blabk box when applied to an alteration of the training data set.
%
The altered data set may be the training data set itself or a subset of it.
%
In both cases, data augmentation through the creation of random input samples is allowed to retain higher predictive performance, by assuming that the predictor is used as an oracle to predict also the additional data.

Extractors based on hypercubic partitioning of the input feature space are usually applied to explain BB regressors.
%
Then, the output value associated to a rule may be a constant numerical value (e.g., \iter{}, \gridex{}, \cart{}) or, otherwise, a linear combination of the input variables (e.g., \cart{}).
%
The procedure adopted to choose the best output value is based on an aggregated computation, and consists of averaging the output prediction values provided by the underlying predictor (for constant outputs) or in the fitting of a linear function of the input variables (otherwise).
%
The aggregation level of the computation depends on the hypercube associated to the rule.
%
Indeed, usually these computations are performed by considering only training instances \emph{inside} a cube, so the resulting rule is \emph{local}.
%
A factorisation of the common operations for both scenarios (constant and non-constant outputs) highlights that the creation of output values for extractors dedicated to regression tasks only differs in the raw aggregated computation described above.
%
As a consequence, the two possible computations may be exchanged without introducing any other alteration in a generic extractor, making it more versatile.

It is possible to enlarge the applicability scope of these extractors to classification tasks thanks to the following consideration.
%
A classification rule based on a hypercube may be associated to a constant output value, that is the string label to be provided as prediction for every instance inside the cube.
%
The label may trivially be the most common label predicted by the underlying predictor applied to all the instances inside the cube.
%
This generalisation enable the adoption for classification tasks of SKE techniques explicitly designed for regression.

\input{figures/fig-gen-pred.tex}

In \Cref{fig:general-pred} are reported examples of predictions provided by a generalised extractor.
%
The three plots follow the same logic as \Cref{fig:general-sim}.

\subsubsection{Output rule creation}

After having selected a set of input space regions and one of corresponding output decision, hypercube-based extractors build a set of rules where each one is composed of a precondition and a postcondition.
%
The precondition is a formal description of a single input region in terms of individual features, for instance by means of value inclusion inside an interval.
%
Hypercubic $d$-dimensional regions may be described through the conjunction of (at most) $d$ interval inclusion conditions.
%
On the other hand, the postcondition is simply the decision calculated for the region on the basis of the task at hand, as previously described.

\subsection{Comparison of Existing Methods}

\gcnote{Fuffa un po' e riempi fin dove arrivi, domani penso al resto}

1. How algorithms partition the input space

2. Different ways for approximating decisions
    + How algorithms approximate decisions

3. How algorithms construct rules

\section{Case Study: \psyke}\label{sec:experiments}

\gcnote{Al posto di parlare di come supportiamo la classificazione, parlerei farei esempi in cui si mostra:
1. how regression related experiments may be re-used for classification
2. focus on how locally-linear approximation may be exploited for regression
3. più tutto ciò che ti sembra sensato presentare dato il discorso di cui sopra.
}

In the following we report the effectiveness of our proposed generalisation implemented for the \iter{} and \gridex{} extraction algorithms, both designed for regression and here applied to explain a classifier.
%
\cart{} is used as benchmark to assess the predictive performance of the modified extractors, since it is a state-of-the-art procedure directly applicable to data sets described by continuous features, without prior discretisation.
%
All the adopted implementations are included in the \psyke{} framework.\footnote{Code of experiments is available at \url{https://github.com/psykei/psyke-python}}

Experiments have been executed on the well-known Iris data set.\footnote{\vurl{https://archive.ics.uci.edu/ml/datasets/iris}}
%
The data set is composed of 150 instances corresponding to Iris flower individuals.
%
Each instance is described by 4 continuous input features (i.e., petal and sepal width and length of the Iris exemplary) and a categorical class label (i.e., the species of the exemplary).
%
Three different species are present in the Iris data set (namely, Setosa, Virginica, and Versicolor) and they are equally balanced (50 individuals per species).

The experiments have been carried out as follows:
%
\begin{inlinelist}
	\item the data set have been randomly split into training and test sets, of equal size;
	\item a $k$-nearest neighbour classifier have been selected to perform the task, with $k=4$;
	\item three different extractors have been used to obtain human-interpretable knowledge from the BB predictions;
	\item the predictive performance of the BB predictor and of the extractors have been graphically compared, in terms of decision boundaries, and numerically assessed, in terms of accuracy and F1 scores. For extractors, also fidelity and readability measurements have been performed.
\end{inlinelist}
%
It worths noticing that the training set is used only to train the models.
%
Conversely, the test set is used only to assess the predictive performance of predictor and extractors.
%
Both sets are constant for each experiment, to better compare the performance under the same conditions.
%
Fidelity of extractors w.r.t.\ the underlying BB have been assessed with the same metrics adopted for the predictive performance.
%
We recall that the fidelity measurements express how well an extractor is able to mimic the underlying predictor.
%
Conversely, predictive performance is calculated between the extractor (or predictor) outputs and the expected values of the test set.
%
Finally, the output knowledge readability is expressed as number of extracted rules.

\subsection{Predictor training}

\input{tables/tab-predictor.tex}

Extraction techniques require an underlying BB to be used as an oracle.
%
For this reason we trained and compared several $k$-NN classifiers, with different values for the $k$ hyper-parameter.
%
Details about the accuracy and F1 scores measured for each model are reported in \Cref{tab:predictor}.
%
The best predictive performance is achieved by the 9-NN.
%
Consequently, in the following all the discussed extractors are applied to it.
%
The decision boundaries of the selected 9-NN are reported in \Cref{fig:knn}.

\subsection{\cart{}}

\input{tables/tab-cart}

The \cart{} extractor has been applied to the 9-NN to extract human-intelligible knowledge in Prolog syntax, without discretising the input data set.
%
Differently from \iter{} and \gridex{}, \cart{} is able to work upon discretised data sets too.
%
Training the model with a maximum leaf amount of 3 gives the following theory, composed of 3 rules---namely, one per each possible class of the Iris data set.

\lstinputlisting[language=Prolog]{listings/iris-rules-cart.pl}

The theory is always exhaustive, since it is always possible to find a leaf classifying an instance.
%
Numerical assessments about the predictive performance and fidelity of the theory extracted with \cart{} are reported in \Cref{tab:cart}.
%
The input space partitioning induced by the theory is reported in \Cref{fig:cart}.
%
In this example, only petal width and length are considered to assign class labels to input instances.

\subsection{\iter{}}

\input{tables/tab-iter}

The \iter{} algorithm has been applied as well to explain the 9-NN.
%
Several combinations of hyper-parameter values have been tested in order to obtain the output knowledge having the highest possible predictive performance and fidelity.
%
\iter{} is based on the following hyper-parameters:
%
\begin{inlinelist}
	\item the size for updating cubes, expressed as fraction of input dimension (i.e., 0.1 means a tenth of the interval between minimum and maximum values of each dimension);
	\item the number of starting points, representing the initial hypercubes;
	\item the minimum number of examples to consider in each cube;
	\item the similarity threshold between adjacent cubes, that is not relevant for classification;
	\item the maximum number of iterations, fixed to 600.
\end{inlinelist}

The results of our experiments for \iter{} are reported in \Cref{tab:iter}.
%
The best predictive performance, achieved with the parameters highlighted in bold font in the Table, correspond to the following rules.
%
\lstinputlisting[language=Prolog]{listings/iris-rules-iter.pl}
%
The input space partitioning induced by the extracted rules is shown in \Cref{fig:iter}.

\subsection{\gridex{}}

\input{tables/tab-gridex}

Finally, as last step of our experiments the \gridex{} extractor has been applied to the 9-NN.
%
Also in this case different values for the hyper-parameters have been explored.
%
We recall that fundamental hyper-parameters for \gridex{} are
%
\begin{inlinelist}
	\item the depth of the recursive partitioning (i.e., how many iterations);
	\item the number of slices to perform at every iteration;
	\item the error threshold used to decide if further divide a hypercube, fixed to 0.1 for all experiments;
	\item the minimum number of examples to consider in each cube, here fixed to 1.
\end{inlinelist}
%
As for the number of slices to be performed, adaptive strategies are preferred to fixed strategies.
%
Experiment results concerning \gridex{} are reported in \Cref{tab:gridex}.
%
The best hyper-parameter values are highlighted in bold font.
%
The semantics of adaptive splitting strategies described by the couple $(a, b)$ is the following: all input dimensions having relevance greater than $a$ are split into $b$ subregions at each iteration.
%
All the other dimensions are not split.
%
Input feature relevance is always scaled in the [0, 1] interval.
%
Corresponding output Prolog theory and input space partitioning are reported in the following and in \Cref{fig:gridex}, respectively.

\lstinputlisting[language=Prolog]{listings/iris-rules-gridex.pl}

Also in this case only one input feature is considered to draw predictions.
%
The partitioning is exhaustive w.r.t.\ the data set, however a small input space region is neglected since the algorithm observed no instances included in it.
%
Differently from \iter{}, \gridex{} is able to detect input dimensions that do not affect the classification.
%
In this manner all the non-relevant antecedents are dropped from the output theory, resulting in a higher human-readability.

\subsection{Discussion}

\input{figures/fig-extractors.tex}

In this Subsection we compare the results of \cart{}, \iter{} and \gridex{} applied to the Iris data set, all summarised in \Cref{fig:extractors}.
%
Results are compared on the basis of readability, fidelity and predictive performance, other than the decision boundaries induced by the extracted rules.
%
As for readability, all the extractors are equivalent w.r.t.\ the amount of rules, since they are able to extract one predictive rule per output class.
%
Conversely, the readability of \iter{} is hindered by the number of antecedents per rule, since it produces a constraint for each input dimension.
%
Under this perspective, \cart{} and \gridex{} are able to keep amongst the rules' conditions only those involving relevant features to perform the classification, resulting in a fourth of the total amount of antecedents w.r.t.\ \iter{}.

The decision boundaries provided by \gridex{} and \iter{} are more similar to those produced by the underlying $k$-NN, but no sensible difference in the classification accuracy are noticeable, since all extractors present a score between 0.94 and 0.95 (we recall that the 9-NN has an accuracy score equal to 0.97).
%
A similar reasoning may be performed about the extractors' fidelity, equal to 0.95 for \cart{} and to 0.97 for \iter{} and \gridex{}.

It worths noting that \gridex{} do not provide a classification rule for a small input space region, since it finds that region as negligible (because there are not data set instances belonging to it).

\section{Conclusions and Future Works}\label{sec:conclusions}



\begin{acknowledgments}
	This paper has been partially supported by
	%
	\begin{inlinelist}
		\item the European Union's Horizon 2020 research and innovation programme under G.A.\ no.\ 101017142 (StairwAI project), and by
		\item the CHIST-ERA IV project CHIST-ERA-19-XAI-005, co-funded by the EU and the Italian MUR (Ministry for University and Research).
	\end{inlinelist}
\end{acknowledgments}

\bibliography{woa-2022-psyke}

\end{document}

%%
%% End of file
