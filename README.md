# Hypercube-based methods for symbolic knowledge extraction: towards a unified model

## Intro

Less fluff on XAI, let's focus directly on SKE

## Background 

as is (magari senza troppi dettagli sugli algoritmi)

## Hypercube-based methods 

### Unified Model

1. Partition the input space
2. Approximate decisions, per-partition
3. Convert partition-decision couples into rules

### Comparison

1. How algorithms partition the input space
2. Different ways for approximating decisions
    + How algorithms approximate decisions
3. How algorithms construct rules

## Case study: Psyke

report experiments here
- focus on how regression related experiments may be re-used for classification
- focus on how locally-linear approximation may be exploited for regression

## Conclusions and future works